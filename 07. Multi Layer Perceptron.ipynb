{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "import pandas as pd\n",
    "original_data = pd.read_csv('./total_price.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불필요한 열 제거\n",
    "del original_data['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 날짜를 인덱스로 변경\n",
    "original_data = original_data.set_index('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l1 ~ l4 Line Setting\n",
    "original_data['l1'] = original_data['l1'].apply(lambda x : str(x)).apply(lambda x : x[1:])\n",
    "original_data['l2'] = original_data['l2'].apply(lambda x : str(x)).apply(lambda x : x[1:])\n",
    "original_data['l3'] = original_data['l3'].apply(lambda x : str(x)).apply(lambda x : x[1:])\n",
    "original_data['l4'] = original_data['l4'].apply(lambda x : str(x)).apply(lambda x : x[1:])\n",
    "\n",
    "# Float\n",
    "original_data['l1'] = original_data['l1'].apply(lambda x : float(x))\n",
    "original_data['l2'] = original_data['l2'].apply(lambda x : float(x))\n",
    "original_data['l3'] = original_data['l3'].apply(lambda x : float(x))\n",
    "original_data['l4'] = original_data['l4'].apply(lambda x : float(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 005930\n",
    "original_data = original_data[original_data['code'] == 5930]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selecting\n",
    "original_data = original_data[original_data.columns[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target 생성\n",
    "original_data['target'] = original_data['close'] - original_data['close'].shift(-1)\n",
    "original_data['target'] = original_data['target'].apply(lambda x : 1 if x > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    505\n",
       "1    397\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_data.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split\n",
    "train = original_data.loc[:'20190331']\n",
    "test = original_data.loc['20190401':]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data MinMaxScaler\n",
    "MIN = train.min()\n",
    "MAX = train.max()\n",
    "train = (train - MIN) / (MAX - MIN)\n",
    "test = (test - MIN) / (MAX - MIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Target Split\n",
    "X_train = train[['open', 'high', 'low', 'close', 'trading_volume']]\n",
    "y_train = train[['target']]\n",
    "X_test = test[['open', 'high', 'low', 'close', 'trading_volume']]\n",
    "y_test = test[['target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# One Hot Encoding\n",
    "from keras.utils.np_utils import to_categorical\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/snap/jupyter/6/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(10, input_dim=5, activation=\"sigmoid\", kernel_initializer=\"glorot_uniform\")`\n",
      "  del sys.path[0]\n",
      "/snap/jupyter/6/lib/python3.7/site-packages/ipykernel_launcher.py:53: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "678/678 [==============================] - 1s 858us/step - loss: 0.7129 - accuracy: 0.4897\n",
      "Epoch 2/30\n",
      "678/678 [==============================] - 0s 9us/step - loss: 0.7096 - accuracy: 0.4882\n",
      "Epoch 3/30\n",
      "678/678 [==============================] - 0s 9us/step - loss: 0.7192 - accuracy: 0.4749\n",
      "Epoch 4/30\n",
      "678/678 [==============================] - 0s 9us/step - loss: 0.6954 - accuracy: 0.5310\n",
      "Epoch 5/30\n",
      "678/678 [==============================] - 0s 8us/step - loss: 0.7113 - accuracy: 0.4720\n",
      "Epoch 6/30\n",
      "678/678 [==============================] - 0s 8us/step - loss: 0.7035 - accuracy: 0.4808\n",
      "Epoch 7/30\n",
      "678/678 [==============================] - 0s 8us/step - loss: 0.7064 - accuracy: 0.4823\n",
      "Epoch 8/30\n",
      "678/678 [==============================] - 0s 7us/step - loss: 0.7043 - accuracy: 0.4867\n",
      "Epoch 9/30\n",
      "678/678 [==============================] - 0s 8us/step - loss: 0.6993 - accuracy: 0.5074\n",
      "Epoch 10/30\n",
      "678/678 [==============================] - 0s 8us/step - loss: 0.6967 - accuracy: 0.5310\n",
      "Epoch 11/30\n",
      "678/678 [==============================] - 0s 9us/step - loss: 0.6976 - accuracy: 0.5074\n",
      "Epoch 12/30\n",
      "678/678 [==============================] - 0s 9us/step - loss: 0.6964 - accuracy: 0.5236\n",
      "Epoch 13/30\n",
      "678/678 [==============================] - 0s 8us/step - loss: 0.7062 - accuracy: 0.4705\n",
      "Epoch 14/30\n",
      "678/678 [==============================] - 0s 9us/step - loss: 0.6940 - accuracy: 0.5265\n",
      "Epoch 15/30\n",
      "678/678 [==============================] - 0s 10us/step - loss: 0.6903 - accuracy: 0.5265\n",
      "Epoch 16/30\n",
      "678/678 [==============================] - 0s 7us/step - loss: 0.6866 - accuracy: 0.5501\n",
      "Epoch 17/30\n",
      "678/678 [==============================] - 0s 9us/step - loss: 0.7038 - accuracy: 0.5029\n",
      "Epoch 18/30\n",
      "678/678 [==============================] - 0s 9us/step - loss: 0.7087 - accuracy: 0.4941\n",
      "Epoch 19/30\n",
      "678/678 [==============================] - 0s 8us/step - loss: 0.6986 - accuracy: 0.5177\n",
      "Epoch 20/30\n",
      "678/678 [==============================] - 0s 7us/step - loss: 0.6947 - accuracy: 0.5280\n",
      "Epoch 21/30\n",
      "678/678 [==============================] - 0s 8us/step - loss: 0.6993 - accuracy: 0.5280\n",
      "Epoch 22/30\n",
      "678/678 [==============================] - 0s 9us/step - loss: 0.6944 - accuracy: 0.5192\n",
      "Epoch 23/30\n",
      "678/678 [==============================] - 0s 8us/step - loss: 0.6908 - accuracy: 0.5354\n",
      "Epoch 24/30\n",
      "678/678 [==============================] - 0s 8us/step - loss: 0.6920 - accuracy: 0.5354\n",
      "Epoch 25/30\n",
      "678/678 [==============================] - 0s 8us/step - loss: 0.6924 - accuracy: 0.5206\n",
      "Epoch 26/30\n",
      "678/678 [==============================] - 0s 9us/step - loss: 0.6890 - accuracy: 0.5560\n",
      "Epoch 27/30\n",
      "678/678 [==============================] - 0s 8us/step - loss: 0.6946 - accuracy: 0.5310\n",
      "Epoch 28/30\n",
      "678/678 [==============================] - 0s 9us/step - loss: 0.6944 - accuracy: 0.5575\n",
      "Epoch 29/30\n",
      "678/678 [==============================] - 0s 8us/step - loss: 0.6918 - accuracy: 0.5487\n",
      "Epoch 30/30\n",
      "678/678 [==============================] - 0s 8us/step - loss: 0.6970 - accuracy: 0.5339\n",
      "모델 평가\n",
      "224/224 [==============================] - 0s 437us/step\n",
      "Accuracy: 0.5758928656578064\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import adam\n",
    "\n",
    "\n",
    "batch_size = 678\n",
    "training_epochs = 30\n",
    "\n",
    "# Multilayer Perceptron (MLP) 생성 \n",
    "model = Sequential() \n",
    "\n",
    "# 첫 번째 Layer (Input layer) \n",
    "model.add(Dense(10, input_dim=5, init='glorot_uniform', activation='sigmoid')) \n",
    "model.add(Dropout(0.3)) # 30% 정도를 Drop \n",
    "\n",
    "# 두 번째 Layer (Hidden layer 1) \n",
    "model.add(Dense(10, activation='sigmoid')) \n",
    "model.add(Dropout(0.1)) \n",
    "\n",
    "# 세 번째 Layer (Hidden layer 2) \n",
    "model.add(Dense(10, activation='sigmoid')) \n",
    "model.add(Dropout(0.1)) \n",
    "\n",
    "# 네 번째 Layer (Hidden layer 3) \n",
    "model.add(Dense(10, activation='sigmoid')) \n",
    "model.add(Dropout(0.1)) \n",
    "\n",
    "# 다섯 번째 Layer (Hidden layer 4) \n",
    "model.add(Dense(10, activation='sigmoid')) \n",
    "model.add(Dropout(0.1)) \n",
    "\n",
    "# 여섯 번째 Layer (Hidden layer 5) \n",
    "model.add(Dense(10, activation='sigmoid')) \n",
    "model.add(Dropout(0.1)) \n",
    "\n",
    "# 일곱 번째 Layer (Hidden layer 6) \n",
    "model.add(Dense(10, activation='sigmoid')) \n",
    "model.add(Dropout(0.1)) \n",
    "\n",
    "# 여덟 번째 Layer (Hidden layer 7) \n",
    "model.add(Dense(10, activation='sigmoid')) \n",
    "model.add(Dropout(0.1)) \n",
    "\n",
    "# 아홉 번째 Layer (Output layer) \n",
    "model.add(Dense(2, activation='softmax')) \n",
    "\n",
    "# Cost function 및 Optimizer 설정 \n",
    "# Multiclass 분류이므로 Cross-entropy 사용 \n",
    "# Adam optimizer 사용 \n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "\n",
    "# model training training_epochs = 15 batch_size = 100 \n",
    "model.fit(X_train, y_train, nb_epoch=training_epochs, batch_size=batch_size) \n",
    "\n",
    "# Model evaluation using test set \n",
    "print('모델 평가') \n",
    "evaluation = model.evaluate(X_test, y_test, batch_size=batch_size) \n",
    "print('Accuracy: ' + str(evaluation[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
