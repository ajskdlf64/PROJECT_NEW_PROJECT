{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset = 67,000 obs\n",
      "Test Dataset = 6,099 obs\n"
     ]
    }
   ],
   "source": [
    "# Library\n",
    "from urllib.request import urlopen\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import webbrowser\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# DataFrame\n",
    "train_dataset = pd.DataFrame()\n",
    "test_dataset = pd.DataFrame()\n",
    "\n",
    "# url connecting\n",
    "url ='https://lab.donutz.co/krx/products'\n",
    "resultXML = urlopen(url)\n",
    "result = resultXML.read()\n",
    "soup = BeautifulSoup(result,'html.parser')\n",
    "soup_string = str(soup)\n",
    "regex = re.compile(r'(\\d{6})')\n",
    "codes = regex.findall(soup_string)\n",
    "codes = [i for i in codes]\n",
    "start_date = '20170101'\n",
    "end_date = '20191231'\n",
    "\n",
    "# 진행과정 계산\n",
    "COUNT = 0\n",
    "    \n",
    "for code in codes[:100] : \n",
    "    \n",
    "    # Crawling\n",
    "    url ='https://lab.donutz.co/krx/products/' + code + '?sdate=' + start_date + '&edate=' + end_date\n",
    "    resultXML = urlopen(url)\n",
    "    result = resultXML.read()\n",
    "    soup = BeautifulSoup(result,'html.parser')\n",
    "    soup_string = str(soup)\n",
    "\n",
    "    # 특수문자 제거\n",
    "    def clean(data):\n",
    "        text = re.sub('[a-zA-Z-=+#/\\?^$@*\\\"※~&%ㆍ!_』:\\\\‘|\\(\\)\\[\\]\\<\\>`\\'{}…》]', '', data)\n",
    "        return text\n",
    "    text = re.split('[,]+',clean(soup_string))\n",
    "    information = []\n",
    "    for i in text:\n",
    "        information.append(i)\n",
    "        \n",
    "    # 데이터프레임으로 변환\n",
    "    data = pd.DataFrame(np.array(information).reshape(-1,15))\n",
    "    data.columns = ['date','open','high','low','close','trading_volume',\\\n",
    "                    'score','index','probability','l1','l2','l3','l4','lgap','lrate']\n",
    "    \n",
    "    # Target 생성\n",
    "    data['Target'] = data['close'].shift(-1)\n",
    "    data = data.dropna()\n",
    "    \n",
    "    # 날짜기준으로 재정렬\n",
    "    data = data.sort_values(by=['date'])\n",
    "\n",
    "    # 날짜 인덱싱\n",
    "    data = data.set_index('date')\n",
    "    \n",
    "    # 데이터 실수화\n",
    "    data['open'] = data['open'].apply(lambda x : np.float(x))\n",
    "    data['high'] = data['high'].apply(lambda x : np.float(x))\n",
    "    data['low'] = data['low'].apply(lambda x : np.float(x))\n",
    "    data['close'] = data['close'].apply(lambda x : np.float(x))\n",
    "    data['trading_volume'] = data['trading_volume'].apply(lambda x : np.float(x))\n",
    "    data['score'] = data['score'].apply(lambda x : np.float(x))\n",
    "    data['index'] = data['index'].apply(lambda x : np.float(x))\n",
    "    data['probability'] = data['probability'].apply(lambda x : np.float(x))\n",
    "    data['l1'] = data['l1'].apply(lambda x : np.float(x))\n",
    "    data['l2'] = data['l2'].apply(lambda x : np.float(x))\n",
    "    data['l3'] = data['l3'].apply(lambda x : np.float(x))\n",
    "    data['l4'] = data['l4'].apply(lambda x : np.float(x))\n",
    "    data['lgap'] = data['lgap'].apply(lambda x : np.float(x))\n",
    "    data['lrate'] = data['lrate'].apply(lambda x : np.float(x))\n",
    "    data['Target'] = data['Target'].apply(lambda x : np.float(x))\n",
    "            \n",
    "    # Rate로 피쳐 변경\n",
    "    data['open_rate'] = (data['open'] - data['open'].shift(1)) / data['open'].shift(1)\n",
    "    data['high_rate'] = (data['high'] - data['high'].shift(1)) / data['high'].shift(1)\n",
    "    data['low_rate'] = (data['low'] - data['low'].shift(1)) / data['low'].shift(1)\n",
    "    data['close_rate'] = (data['close'] - data['close'].shift(1)) / data['close'].shift(1)\n",
    "    data['trading_volume_rate'] = (data['trading_volume'] - data['trading_volume'].shift(1))\n",
    "    data['score_rate'] = (data['score'] - data['score'].shift(1)) / data['score'].shift(1)\n",
    "    data['index_rate'] = (data['index'] - data['index'].shift(1)) / data['index'].shift(1)\n",
    "    data['probability_rate'] = (data['probability'] - data['probability'].shift(1))\n",
    "    data['l1_rate'] = (data['l1'] - data['l1'].shift(1)) / data['l1'].shift(1)\n",
    "    data['l2_rate'] = (data['l2'] - data['l2'].shift(1)) / data['l2'].shift(1)\n",
    "    data['l3_rate'] = (data['l3'] - data['l3'].shift(1)) / data['l3'].shift(1)\n",
    "    data['l4_rate'] = (data['l4'] - data['l4'].shift(1)) / data['l4'].shift(1)\n",
    "    data['lgap_rate'] = (data['lgap'] - data['lgap'].shift(1))\n",
    "    data['lrate_rate'] = (data['lrate'] - data['lrate'].shift(1))\n",
    "\n",
    "    # Target 형태 변경\n",
    "    data['prediction'] = 100 * (data['Target'] - data['close']) / data['close']\n",
    "    \n",
    "    # 결측값 제거\n",
    "    data = data.dropna()\n",
    "    \n",
    "    # 기존변수 제거\n",
    "    data = data[['open_rate', 'high_rate', 'low_rate', 'close_rate', 'trading_volume_rate',\\\n",
    "                 'score_rate', 'index_rate', 'probability_rate', 'l1_rate', 'l2_rate',\\\n",
    "                  'l3_rate', 'l4_rate', 'lgap_rate', 'lrate_rate', 'prediction']]\n",
    "    \n",
    "    # Train Test Split\n",
    "    train = data['20170101':'20190930']\n",
    "    test = data['20191001':'20191231']    \n",
    "    \n",
    "    # 데이터 저장\n",
    "    train_dataset = train_dataset.append(train)\n",
    "    test_dataset = test_dataset.append(test)\n",
    "    \n",
    "print(\"Train Dataset = {:,} obs\" .format(len(train_dataset)))\n",
    "print(\"Test Dataset = {:,} obs\" .format(len(test_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "train_X = train_dataset[train_dataset.columns[:-1]]\n",
    "train_Y = train_dataset[train_dataset.columns[-1:]]\n",
    "\n",
    "# Test\n",
    "test_X = test_dataset[test_dataset.columns[:-1]]\n",
    "test_Y = test_dataset[test_dataset.columns[-1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 52)                780       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 39)                2067      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 26)                1040      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 27        \n",
      "=================================================================\n",
      "Total params: 3,914\n",
      "Trainable params: 3,914\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50250 samples, validate on 16750 samples\n",
      "Epoch 1/40\n",
      "50250/50250 [==============================] - 1s 17us/sample - loss: 26157927159.4357 - val_loss: 642.3950\n",
      "Epoch 2/40\n",
      "50250/50250 [==============================] - 0s 3us/sample - loss: 115.5642 - val_loss: 542.8262\n",
      "Epoch 3/40\n",
      "50250/50250 [==============================] - 0s 3us/sample - loss: 98.1295 - val_loss: 150.2839\n",
      "Epoch 4/40\n",
      "50250/50250 [==============================] - 0s 3us/sample - loss: 55.0735 - val_loss: 67.6334\n",
      "Epoch 5/40\n",
      "50250/50250 [==============================] - 0s 4us/sample - loss: 48.7323 - val_loss: 37.7556\n",
      "Epoch 6/40\n",
      "50250/50250 [==============================] - 0s 4us/sample - loss: 50.0943 - val_loss: 473.4696\n",
      "Epoch 7/40\n",
      "50250/50250 [==============================] - 0s 4us/sample - loss: 74.7882 - val_loss: 115.8204\n",
      "Epoch 8/40\n",
      "50250/50250 [==============================] - 0s 4us/sample - loss: 52.4842 - val_loss: 93.0838\n",
      "Epoch 9/40\n",
      "50250/50250 [==============================] - 0s 4us/sample - loss: 104.9147 - val_loss: 135.1679\n",
      "Epoch 10/40\n",
      "50250/50250 [==============================] - 0s 4us/sample - loss: 36.4156 - val_loss: 135.2149\n",
      "Epoch 11/40\n",
      "50250/50250 [==============================] - 0s 4us/sample - loss: 35.6943 - val_loss: 135.0579\n",
      "Epoch 12/40\n",
      "50250/50250 [==============================] - 0s 4us/sample - loss: 35.0126 - val_loss: 134.8444\n",
      "Epoch 13/40\n",
      "50250/50250 [==============================] - 0s 4us/sample - loss: 34.3509 - val_loss: 134.6524\n",
      "Epoch 14/40\n",
      "50250/50250 [==============================] - 0s 4us/sample - loss: 33.7132 - val_loss: 134.4673\n",
      "Epoch 15/40\n",
      "50250/50250 [==============================] - 0s 4us/sample - loss: 33.1237 - val_loss: 134.2617\n",
      "Epoch 16/40\n",
      "50250/50250 [==============================] - 0s 4us/sample - loss: 32.5463 - val_loss: 134.0432\n",
      "Epoch 17/40\n",
      "50250/50250 [==============================] - 0s 4us/sample - loss: 31.9915 - val_loss: 133.8552\n",
      "Epoch 18/40\n",
      "50250/50250 [==============================] - 0s 4us/sample - loss: 31.4856 - val_loss: 133.6222\n",
      "Epoch 19/40\n",
      "50250/50250 [==============================] - 0s 4us/sample - loss: 30.9964 - val_loss: 133.3857\n",
      "Epoch 20/40\n",
      "50250/50250 [==============================] - 0s 4us/sample - loss: 30.5333 - val_loss: 133.1639\n",
      "Epoch 21/40\n",
      "50250/50250 [==============================] - 0s 4us/sample - loss: 30.1103 - val_loss: 132.9368\n",
      "Epoch 22/40\n",
      "50250/50250 [==============================] - 0s 4us/sample - loss: 29.7210 - val_loss: 132.6925\n",
      "Epoch 23/40\n",
      "50250/50250 [==============================] - 0s 4us/sample - loss: 29.3496 - val_loss: 132.4384\n",
      "Epoch 24/40\n",
      "50250/50250 [==============================] - 0s 4us/sample - loss: 29.0043 - val_loss: 132.1866\n",
      "Epoch 25/40\n",
      "50250/50250 [==============================] - 0s 4us/sample - loss: 28.6783 - val_loss: 131.9391\n",
      "Epoch 26/40\n",
      "50250/50250 [==============================] - 0s 4us/sample - loss: 28.3918 - val_loss: 131.6565\n",
      "Epoch 27/40\n",
      "50250/50250 [==============================] - 0s 4us/sample - loss: 28.1042 - val_loss: 131.4203\n",
      "Epoch 28/40\n",
      "50250/50250 [==============================] - 0s 4us/sample - loss: 27.8497 - val_loss: 131.1148\n",
      "Epoch 29/40\n",
      "50250/50250 [==============================] - 0s 4us/sample - loss: 27.6025 - val_loss: 130.7975\n",
      "Epoch 30/40\n",
      "50250/50250 [==============================] - 0s 4us/sample - loss: 27.3759 - val_loss: 130.5099\n",
      "Epoch 31/40\n",
      "50250/50250 [==============================] - 0s 4us/sample - loss: 27.1605 - val_loss: 130.1998\n",
      "Epoch 32/40\n",
      "50250/50250 [==============================] - 0s 4us/sample - loss: 26.9602 - val_loss: 129.9124\n",
      "Epoch 33/40\n",
      "50250/50250 [==============================] - 0s 4us/sample - loss: 26.7738 - val_loss: 129.5729\n",
      "Epoch 34/40\n",
      "50250/50250 [==============================] - 0s 4us/sample - loss: 26.5738 - val_loss: 129.2591\n",
      "Epoch 35/40\n",
      "50250/50250 [==============================] - 0s 4us/sample - loss: 26.4033 - val_loss: 128.8985\n",
      "Epoch 36/40\n",
      "50250/50250 [==============================] - 0s 4us/sample - loss: 26.2427 - val_loss: 128.5581\n",
      "Epoch 37/40\n",
      "50250/50250 [==============================] - 0s 4us/sample - loss: 26.0278 - val_loss: 128.0027\n",
      "Epoch 38/40\n",
      "50250/50250 [==============================] - 0s 3us/sample - loss: 25.8173 - val_loss: 127.3982\n",
      "Epoch 39/40\n",
      "50250/50250 [==============================] - 0s 4us/sample - loss: 25.6590 - val_loss: 127.0388\n",
      "Epoch 40/40\n",
      "50250/50250 [==============================] - 0s 4us/sample - loss: 25.5141 - val_loss: 126.6406\n"
     ]
    }
   ],
   "source": [
    "# Library\n",
    "import tensorflow as tf\n",
    "\n",
    "# Model Build\n",
    "model = tf.keras.Sequential([\n",
    "                             tf.keras.layers.Dense(units=52, activation='relu', input_shape=(14,)),\n",
    "                             tf.keras.layers.Dense(units=39, activation='relu'),\n",
    "                             tf.keras.layers.Dense(units=26, activation='relu'),\n",
    "                             tf.keras.layers.Dense(units=1)\n",
    "])\n",
    "\n",
    "# Model Compile\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=.07), loss='mse')\n",
    "model.summary()\n",
    "\n",
    "# Model Learning\n",
    "history = model.fit(train_X, train_Y, epochs=40, batch_size=1024, validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# loss 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'], 'b-', label='loss')\n",
    "plt.plot(history.history['val_loss'], 'r--', label='val_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nvadmin/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>model_predicton</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20191001</td>\n",
       "      <td>-5.185185</td>\n",
       "      <td>-0.260597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20191002</td>\n",
       "      <td>1.562500</td>\n",
       "      <td>-0.260597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20191004</td>\n",
       "      <td>-0.128205</td>\n",
       "      <td>-0.260597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20191007</td>\n",
       "      <td>0.513479</td>\n",
       "      <td>-0.260597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20191008</td>\n",
       "      <td>0.127714</td>\n",
       "      <td>-0.260597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20191220</td>\n",
       "      <td>-1.175214</td>\n",
       "      <td>-0.260597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20191223</td>\n",
       "      <td>-0.540541</td>\n",
       "      <td>-0.260597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20191224</td>\n",
       "      <td>0.326087</td>\n",
       "      <td>-0.260597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20191226</td>\n",
       "      <td>1.408451</td>\n",
       "      <td>-0.260597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20191227</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.260597</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6099 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          prediction  model_predicton\n",
       "date                                 \n",
       "20191001   -5.185185        -0.260597\n",
       "20191002    1.562500        -0.260597\n",
       "20191004   -0.128205        -0.260597\n",
       "20191007    0.513479        -0.260597\n",
       "20191008    0.127714        -0.260597\n",
       "...              ...              ...\n",
       "20191220   -1.175214        -0.260597\n",
       "20191223   -0.540541        -0.260597\n",
       "20191224    0.326087        -0.260597\n",
       "20191226    1.408451        -0.260597\n",
       "20191227    0.000000        -0.260597\n",
       "\n",
       "[6099 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_Y['model_predicton'] = model.predict(test_X).reshape(-1)\n",
    "test_Y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
