{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**01. 데이터 로딩**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>score</th>\n",
       "      <th>index</th>\n",
       "      <th>probability</th>\n",
       "      <th>l1</th>\n",
       "      <th>l2</th>\n",
       "      <th>l3</th>\n",
       "      <th>l4</th>\n",
       "      <th>lgap</th>\n",
       "      <th>lrate</th>\n",
       "      <th>open_high</th>\n",
       "      <th>open_low</th>\n",
       "      <th>open_close</th>\n",
       "      <th>zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4.334975</td>\n",
       "      <td>-2.758621</td>\n",
       "      <td>-2.760736</td>\n",
       "      <td>-1.017294</td>\n",
       "      <td>12.589118</td>\n",
       "      <td>1.329195</td>\n",
       "      <td>0.887480</td>\n",
       "      <td>47.114</td>\n",
       "      <td>-1.916462</td>\n",
       "      <td>-1.901902</td>\n",
       "      <td>-1.886792</td>\n",
       "      <td>-1.871102</td>\n",
       "      <td>6.293419</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.016478</td>\n",
       "      <td>-0.020597</td>\n",
       "      <td>0.002060</td>\n",
       "      <td>+3 ~ +10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.338826</td>\n",
       "      <td>0.405268</td>\n",
       "      <td>-8.517350</td>\n",
       "      <td>-6.680370</td>\n",
       "      <td>13.340528</td>\n",
       "      <td>1.641324</td>\n",
       "      <td>0.672944</td>\n",
       "      <td>27.960</td>\n",
       "      <td>1.202405</td>\n",
       "      <td>-3.112245</td>\n",
       "      <td>-7.588358</td>\n",
       "      <td>-12.235169</td>\n",
       "      <td>7.504392</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.007114</td>\n",
       "      <td>-0.115854</td>\n",
       "      <td>-0.077236</td>\n",
       "      <td>-3 ~ -1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-11.077236</td>\n",
       "      <td>-4.339051</td>\n",
       "      <td>0.574713</td>\n",
       "      <td>3.524229</td>\n",
       "      <td>12.721548</td>\n",
       "      <td>1.597365</td>\n",
       "      <td>0.631272</td>\n",
       "      <td>23.643</td>\n",
       "      <td>-2.920792</td>\n",
       "      <td>-0.579252</td>\n",
       "      <td>2.080990</td>\n",
       "      <td>5.129753</td>\n",
       "      <td>6.999422</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.083429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.074286</td>\n",
       "      <td>-3 ~ -1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.257143</td>\n",
       "      <td>3.059072</td>\n",
       "      <td>5.257143</td>\n",
       "      <td>3.829787</td>\n",
       "      <td>12.550566</td>\n",
       "      <td>1.597365</td>\n",
       "      <td>0.631272</td>\n",
       "      <td>23.643</td>\n",
       "      <td>2.447731</td>\n",
       "      <td>3.442797</td>\n",
       "      <td>4.517906</td>\n",
       "      <td>5.683123</td>\n",
       "      <td>6.734592</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.060803</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.059718</td>\n",
       "      <td>-1 ~ +1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.948969</td>\n",
       "      <td>3.377687</td>\n",
       "      <td>5.320304</td>\n",
       "      <td>-0.102459</td>\n",
       "      <td>12.772218</td>\n",
       "      <td>1.597365</td>\n",
       "      <td>0.631272</td>\n",
       "      <td>23.643</td>\n",
       "      <td>0.796416</td>\n",
       "      <td>1.638505</td>\n",
       "      <td>2.530311</td>\n",
       "      <td>3.476372</td>\n",
       "      <td>6.398595</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.025381</td>\n",
       "      <td>-0.015228</td>\n",
       "      <td>-0.010152</td>\n",
       "      <td>-3 ~ -1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1901794</th>\n",
       "      <td>-0.371496</td>\n",
       "      <td>-0.468227</td>\n",
       "      <td>-0.169205</td>\n",
       "      <td>0.337838</td>\n",
       "      <td>6.994850</td>\n",
       "      <td>7.957877</td>\n",
       "      <td>2.397895</td>\n",
       "      <td>79.010</td>\n",
       "      <td>-0.217210</td>\n",
       "      <td>-0.067227</td>\n",
       "      <td>0.084531</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>5.278115</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.008814</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006780</td>\n",
       "      <td>-1 ~ +1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1901795</th>\n",
       "      <td>0.677966</td>\n",
       "      <td>0.840054</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.268988</td>\n",
       "      <td>7.913155</td>\n",
       "      <td>3.044522</td>\n",
       "      <td>79.751</td>\n",
       "      <td>0.703282</td>\n",
       "      <td>0.420451</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>-0.152698</td>\n",
       "      <td>5.779199</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.010438</td>\n",
       "      <td>-0.004040</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1 ~ +1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1901796</th>\n",
       "      <td>-1.043771</td>\n",
       "      <td>-1.066311</td>\n",
       "      <td>-0.642326</td>\n",
       "      <td>-0.033670</td>\n",
       "      <td>7.442493</td>\n",
       "      <td>7.909489</td>\n",
       "      <td>3.044522</td>\n",
       "      <td>79.751</td>\n",
       "      <td>-0.764882</td>\n",
       "      <td>-0.552671</td>\n",
       "      <td>-0.337382</td>\n",
       "      <td>-0.118946</td>\n",
       "      <td>5.420535</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.010208</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010208</td>\n",
       "      <td>+1 ~ +3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1901797</th>\n",
       "      <td>-0.306227</td>\n",
       "      <td>-1.111485</td>\n",
       "      <td>-0.918680</td>\n",
       "      <td>-1.481980</td>\n",
       "      <td>6.194405</td>\n",
       "      <td>7.896553</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>77.297</td>\n",
       "      <td>-1.390751</td>\n",
       "      <td>-1.296733</td>\n",
       "      <td>-1.201760</td>\n",
       "      <td>-1.105818</td>\n",
       "      <td>5.198497</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002048</td>\n",
       "      <td>-0.006143</td>\n",
       "      <td>-0.001706</td>\n",
       "      <td>-3 ~ -1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1901798</th>\n",
       "      <td>-0.170648</td>\n",
       "      <td>4.529973</td>\n",
       "      <td>-1.030220</td>\n",
       "      <td>4.923077</td>\n",
       "      <td>9.109525</td>\n",
       "      <td>7.896553</td>\n",
       "      <td>3.044522</td>\n",
       "      <td>79.751</td>\n",
       "      <td>7.476636</td>\n",
       "      <td>4.726156</td>\n",
       "      <td>1.953058</td>\n",
       "      <td>-0.842938</td>\n",
       "      <td>7.246724</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.049231</td>\n",
       "      <td>-0.014701</td>\n",
       "      <td>0.049231</td>\n",
       "      <td>+10 ~ +30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1901799 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              open      high       low     close     volume     score  \\\n",
       "0        -4.334975 -2.758621 -2.760736 -1.017294  12.589118  1.329195   \n",
       "1         1.338826  0.405268 -8.517350 -6.680370  13.340528  1.641324   \n",
       "2       -11.077236 -4.339051  0.574713  3.524229  12.721548  1.597365   \n",
       "3         5.257143  3.059072  5.257143  3.829787  12.550566  1.597365   \n",
       "4         6.948969  3.377687  5.320304 -0.102459  12.772218  1.597365   \n",
       "...            ...       ...       ...       ...        ...       ...   \n",
       "1901794  -0.371496 -0.468227 -0.169205  0.337838   6.994850  7.957877   \n",
       "1901795   0.677966  0.840054  0.271186  0.000000   8.268988  7.913155   \n",
       "1901796  -1.043771 -1.066311 -0.642326 -0.033670   7.442493  7.909489   \n",
       "1901797  -0.306227 -1.111485 -0.918680 -1.481980   6.194405  7.896553   \n",
       "1901798  -0.170648  4.529973 -1.030220  4.923077   9.109525  7.896553   \n",
       "\n",
       "            index  probability        l1        l2        l3         l4  \\\n",
       "0        0.887480       47.114 -1.916462 -1.901902 -1.886792  -1.871102   \n",
       "1        0.672944       27.960  1.202405 -3.112245 -7.588358 -12.235169   \n",
       "2        0.631272       23.643 -2.920792 -0.579252  2.080990   5.129753   \n",
       "3        0.631272       23.643  2.447731  3.442797  4.517906   5.683123   \n",
       "4        0.631272       23.643  0.796416  1.638505  2.530311   3.476372   \n",
       "...           ...          ...       ...       ...       ...        ...   \n",
       "1901794  2.397895       79.010 -0.217210 -0.067227  0.084531   0.238095   \n",
       "1901795  3.044522       79.751  0.703282  0.420451  0.135135  -0.152698   \n",
       "1901796  3.044522       79.751 -0.764882 -0.552671 -0.337382  -0.118946   \n",
       "1901797  1.945910       77.297 -1.390751 -1.296733 -1.201760  -1.105818   \n",
       "1901798  3.044522       79.751  7.476636  4.726156  1.953058  -0.842938   \n",
       "\n",
       "             lgap  lrate  open_high  open_low  open_close       zone  \n",
       "0        6.293419    6.0   0.016478 -0.020597    0.002060   +3 ~ +10  \n",
       "1        7.504392   20.0   0.007114 -0.115854   -0.077236    -3 ~ -1  \n",
       "2        6.999422   12.0   0.083429  0.000000    0.074286    -3 ~ -1  \n",
       "3        6.734592    9.0   0.060803  0.000000    0.059718    -1 ~ +1  \n",
       "4        6.398595    6.0   0.025381 -0.015228   -0.010152    -3 ~ -1  \n",
       "...           ...    ...        ...       ...         ...        ...  \n",
       "1901794  5.278115    1.0   0.008814  0.000000    0.006780    -1 ~ +1  \n",
       "1901795  5.779199    2.0   0.010438 -0.004040    0.000000    -1 ~ +1  \n",
       "1901796  5.420535    2.0   0.010208  0.000000    0.010208    +1 ~ +3  \n",
       "1901797  5.198497    1.0   0.002048 -0.006143   -0.001706    -3 ~ -1  \n",
       "1901798  7.246724    9.0   0.049231 -0.014701    0.049231  +10 ~ +30  \n",
       "\n",
       "[1901799 rows x 18 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 라이브러리\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 데이터 로딩\n",
    "dataset = pd.read_csv('./final_dataset.csv')\n",
    "\n",
    "# 불필요한 열 제거\n",
    "del dataset['Unnamed: 0']\n",
    "\n",
    "# 데이터 보기\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**02. Train 데이터와 Test 데이터 분리**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 구역 숫자로 변환\n",
    "def zone(x) :\n",
    "    if x == '-30 ~ -10' : return 0\n",
    "    elif x == '-10 ~ -3' : return 1\n",
    "    elif x == '-3 ~ -1' : return 2\n",
    "    elif x == '-1 ~ +1' : return 3\n",
    "    elif x == '+1 ~ +3' : return 4\n",
    "    elif x == '+3 ~ +10' : return 5\n",
    "    elif x == '+10 ~ +20' : return 6\n",
    "    else : return 7\n",
    "        \n",
    "dataset['zone'] = dataset['zone'].apply(lambda x : zone(x))\n",
    "\n",
    "# 어레이로 데이터 변경\n",
    "dataset = np.array(dataset)\n",
    "\n",
    "# 80%를 학습하는데 이용\n",
    "train_idx = int(len(dataset) * 0.8)\n",
    "train_X, train_Y = dataset[:train_idx, :-1], dataset[:train_idx, -1]\n",
    "test_X, test_Y = dataset[train_idx:, :-1], dataset[train_idx:, -1]\n",
    "\n",
    "# 카테고리 지정\n",
    "import tensorflow as tf\n",
    "train_Y = tf.keras.utils.to_categorical(train_Y, num_classes=8)\n",
    "test_Y = tf.keras.utils.to_categorical(test_Y, num_classes=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**03. Model Build**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 10)                180       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 88        \n",
      "=================================================================\n",
      "Total params: 378\n",
      "Trainable params: 378\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "                             tf.keras.layers.Dense(units=10,activation='relu',input_shape=(train_X.shape[1],)),\n",
    "                             tf.keras.layers.Dense(units=10,activation='relu'),\n",
    "                             tf.keras.layers.Dense(units=8, activation='softmax')\n",
    "])\n",
    "        \n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.07), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**04. Learning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1141079 samples, validate on 380360 samples\n",
      "Epoch 1/25\n",
      "1141079/1141079 [==============================] - 2s 2us/sample - loss: 1.3526 - accuracy: 0.4580 - val_loss: 1.2240 - val_accuracy: 0.4695\n",
      "Epoch 2/25\n",
      "1141079/1141079 [==============================] - 1s 1us/sample - loss: 1.2272 - accuracy: 0.4708 - val_loss: 1.2209 - val_accuracy: 0.4705\n",
      "Epoch 3/25\n",
      "1141079/1141079 [==============================] - 1s 1us/sample - loss: 1.2228 - accuracy: 0.4717 - val_loss: 1.2212 - val_accuracy: 0.4710\n",
      "Epoch 4/25\n",
      "1141079/1141079 [==============================] - 1s 1us/sample - loss: 1.2223 - accuracy: 0.4717 - val_loss: 1.2204 - val_accuracy: 0.4704\n",
      "Epoch 5/25\n",
      "1141079/1141079 [==============================] - 1s 1us/sample - loss: 1.2230 - accuracy: 0.4718 - val_loss: 1.2237 - val_accuracy: 0.4702\n",
      "Epoch 6/25\n",
      "1141079/1141079 [==============================] - 1s 1us/sample - loss: 1.2219 - accuracy: 0.4723 - val_loss: 1.2223 - val_accuracy: 0.4714\n",
      "Epoch 7/25\n",
      "1141079/1141079 [==============================] - 1s 1us/sample - loss: 1.2208 - accuracy: 0.4724 - val_loss: 1.2172 - val_accuracy: 0.4714\n",
      "Epoch 8/25\n",
      "1141079/1141079 [==============================] - 1s 1us/sample - loss: 1.2197 - accuracy: 0.4723 - val_loss: 1.2154 - val_accuracy: 0.4715\n",
      "Epoch 9/25\n",
      "1141079/1141079 [==============================] - 1s 1us/sample - loss: 1.2196 - accuracy: 0.4724 - val_loss: 1.2147 - val_accuracy: 0.4713\n",
      "Epoch 10/25\n",
      "1141079/1141079 [==============================] - 1s 1us/sample - loss: 1.2195 - accuracy: 0.4724 - val_loss: 1.2164 - val_accuracy: 0.4714\n",
      "Epoch 11/25\n",
      "1141079/1141079 [==============================] - 1s 1us/sample - loss: 1.2193 - accuracy: 0.4724 - val_loss: 1.2157 - val_accuracy: 0.4711\n",
      "Epoch 12/25\n",
      "1141079/1141079 [==============================] - 1s 1us/sample - loss: 1.2195 - accuracy: 0.4724 - val_loss: 1.2189 - val_accuracy: 0.4709\n",
      "Epoch 13/25\n",
      "1141079/1141079 [==============================] - 1s 1us/sample - loss: 1.2190 - accuracy: 0.4724 - val_loss: 1.2137 - val_accuracy: 0.4718\n",
      "Epoch 14/25\n",
      "1141079/1141079 [==============================] - 1s 1us/sample - loss: 1.2193 - accuracy: 0.4726 - val_loss: 1.2167 - val_accuracy: 0.4709\n",
      "Epoch 15/25\n",
      "1141079/1141079 [==============================] - 1s 1us/sample - loss: 1.2189 - accuracy: 0.4724 - val_loss: 1.2144 - val_accuracy: 0.4707\n",
      "Epoch 16/25\n",
      "1141079/1141079 [==============================] - 1s 1us/sample - loss: 1.2190 - accuracy: 0.4725 - val_loss: 1.2139 - val_accuracy: 0.4719\n",
      "Epoch 17/25\n",
      "1141079/1141079 [==============================] - 1s 1us/sample - loss: 1.2194 - accuracy: 0.4725 - val_loss: 1.2145 - val_accuracy: 0.4710\n",
      "Epoch 18/25\n",
      "1141079/1141079 [==============================] - 1s 1us/sample - loss: 1.2203 - accuracy: 0.4725 - val_loss: 1.2189 - val_accuracy: 0.4712\n",
      "Epoch 19/25\n",
      "1141079/1141079 [==============================] - 1s 1us/sample - loss: 1.2194 - accuracy: 0.4724 - val_loss: 1.2172 - val_accuracy: 0.4707\n",
      "Epoch 20/25\n",
      "1141079/1141079 [==============================] - 1s 1us/sample - loss: 1.2191 - accuracy: 0.4725 - val_loss: 1.2155 - val_accuracy: 0.4717\n",
      "Epoch 21/25\n",
      "1141079/1141079 [==============================] - 1s 1us/sample - loss: 1.2193 - accuracy: 0.4725 - val_loss: 1.2155 - val_accuracy: 0.4715\n",
      "Epoch 22/25\n",
      "1141079/1141079 [==============================] - 1s 1us/sample - loss: 1.2188 - accuracy: 0.4727 - val_loss: 1.2140 - val_accuracy: 0.4717\n",
      "Epoch 23/25\n",
      "1141079/1141079 [==============================] - 1s 1us/sample - loss: 1.2190 - accuracy: 0.4725 - val_loss: 1.2146 - val_accuracy: 0.4718\n",
      "Epoch 24/25\n",
      "1141079/1141079 [==============================] - 1s 1us/sample - loss: 1.2190 - accuracy: 0.4728 - val_loss: 1.2216 - val_accuracy: 0.4705\n",
      "Epoch 25/25\n",
      "1141079/1141079 [==============================] - 1s 1us/sample - loss: 1.2191 - accuracy: 0.4724 - val_loss: 1.2186 - val_accuracy: 0.4704\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_X, train_Y, epochs=25, batch_size=4096, validation_split=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**05. Test Evaluate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "380360/380360 [==============================] - 9s 23us/sample - loss: 1.0913 - accuracy: 0.5472\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0912521941038271, 0.54718685]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_X, test_Y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
